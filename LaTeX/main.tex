
“Does explicit object-level spatial structure improve generalization and robustness in imitation-based planning?”
"Can CLIP-based representations of different abstraction levels improve generalization and robustness in imitation-based planning and reinforcement learning?"
"Does CLIP-based alignment between simple simulation and complex environments improve generalization and robustness in imitation-based planning and reinforcement learning?"
Or more generally:
"Does CLIP solve the sim-to-real gap for imitation-based planning and reinforcement learning?"

Sub-questions:
"Can CLIP-based help form abstract representations through various encoders or should all abstractions be formed through a single transformer architecture?"
"Can CLIP-based encoders serve as the foundation for building multi-level abstractions and therefore serve as possible more fine-grained update mechanisms for imitation-based learning and reinforcement learning?"

CLIP-variation: Instead of just calculating the dot product between image and text embeddings, we can also consider using addition of embeddings and then contrasting against the set of all other embeddings.
\paragraph{Introduction}



\paragraph{Related Work}



\paragraph{Method}



\paragraph{Results}



\paragraph{Discussion}



\paragraph{Conclusion}



\paragraph{Future Work}